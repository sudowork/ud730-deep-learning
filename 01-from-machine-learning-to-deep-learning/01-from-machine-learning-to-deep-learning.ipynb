{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Machine Learning to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification\n",
    "\n",
    "Classification is taking an input and assigning a label to it. The supervised portion of it comes from having a training dataset of already labeled examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "$$ Wx + b = y $$\n",
    "\n",
    "Scores ($y_i$) are also called _logits_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Function\n",
    "\n",
    "\n",
    "Turns scores into proper probabilities. Proper probabilities sum to 1. They will be large when scores are large; small when scores are small.\n",
    "\n",
    "$$ S(y_i) = \\frac{e^{y_i}}{\\sum\\limits_{j}e^{y_j}} $$\n",
    "\n",
    "### Quiz: Softmax\n",
    "\n",
    "\n",
    "Behavior when scores are multiplied by 10: Probabilities get closer to 0 and 1 (more extreme since deviation of $e^{y_i}$ is much higher).\n",
    "\n",
    "Behavior when scores are divided by 10: Probabilities get closer to uniform distribution ($\\frac{1}{n}$) since deviations becomes much smaller and scores are more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109cebd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Softmax.\"\"\"\n",
    "\n",
    "scores = [3.0, 1.0, 0.2]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "print(softmax(scores))\n",
    "\n",
    "# Plot softmax curves\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(-2.0, 6.0, 0.1)\n",
    "scores = np.vstack([x, np.ones_like(x), 0.2 * np.ones_like(x)])\n",
    "\n",
    "plt.plot(x, softmax(scores).T, linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "Encode $n$ labels into a vector of $n$ length, where each vector contains one element that is equal to $1$, and the rest are $0$. The position of the 1 element encodes each label.\n",
    "\n",
    "\\\\[\n",
    "a \\rightarrow \\begin{pmatrix} 1\\\\0\\\\0\\\\0 \\end{pmatrix}\n",
    "b \\rightarrow \\begin{pmatrix} 0\\\\1\\\\0\\\\0 \\end{pmatrix}\n",
    "c \\rightarrow \\begin{pmatrix} 0\\\\0\\\\1\\\\0 \\end{pmatrix}\n",
    "d \\rightarrow \\begin{pmatrix} 0\\\\0\\\\0\\\\1 \\end{pmatrix}\n",
    "\\\\]\n",
    "\n",
    "One down-side of one-hot encoding is that it will result in large vectors if the number of labels is large. This can be solved with _embeddings_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "Cross entropy is a natural way to measure the distance between two probability vectors. $S(y)$ is the softmax function applied to the logits $y$. $L$ is the one-hot encoded labels.\n",
    "\n",
    "$$ D(S, L) = -\\sum\\limits_{i} L_i \\log(S_i) $$\n",
    "\n",
    "For example:\n",
    "\n",
    "\\\\[\n",
    "S(y) = \\begin{pmatrix} 0.7 \\\\\\ 0.2 \\\\\\ 0.1 \\end{pmatrix}\n",
    "L_i = \\begin{pmatrix} 1 \\\\\\ 0 \\\\\\ 0 \\end{pmatrix}\n",
    "\\\\]\n",
    "\n",
    "Cross-entropy is not symmetric: $D(S, L) \\ne D(L, S)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Minimizing Cross Entropy\n",
    "\n",
    "Loss $\\mathcal{L}$ in this definition is the average cross entropy distance over the entire training set.\n",
    "\n",
    "$$ \\mathcal{L}(W, b) = \\frac{1}{N} \\sum\\limits_i D(S(Wx_i + b), L_i) $$\n",
    "\n",
    "Loss is a function of the weights and the biases. We need to minimize loss; one way to do so is gradient descent.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "Use gradient descent to minimize loss. Find the derivative of the loss function $\\mathcal{L}$ and apply a learning rate $\\alpha$.\n",
    "\n",
    "$$ -\\alpha\\Delta \\mathcal{L}(W, b) $$\n",
    "\n",
    "![Gradient Descent](gradient-descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Multinomial Logistic Classification\n",
    "\n",
    "Feed input $x$ into linear model $y(x)=Wx+b$ to produce logits.\n",
    "\n",
    "With logits $y$, feed them into the softmax function $S(y_i) = \\frac{e^{y_i}}{\\sum\\limits_{j}e^{y_j}}$ to produce probabilities.\n",
    "\n",
    "With probabilities $S(y)$ and one-hot-encoded labels $L$, determine the cross entropy $D(S, L) = -\\sum\\limits_{i} L_i \\log(S_i)$.\n",
    "\n",
    "![Depiction of Multinomial Logistic Classification](multinomial-logistic-classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Inputs and Initial Weights\n",
    "\n",
    "### Normalizing Inputs\n",
    "\n",
    "Due to floating point error, we want to maintain numerical stability. One way to do this is to using the following guiding principal. Each variable $x_i$ should have a mean of $0$ and equal variance $\\sigma(x_i) = \\sigma(x_j)$.\n",
    "\n",
    "When variables are badly conditioned (unevenly scaled), then the optimizer has to do a lot of searching (more iterations/compute).\n",
    "\n",
    "![Feature Scaling](scaling.png)\n",
    "\n",
    "You can normalize an input by:\n",
    "\n",
    "$$ \\mbox{normalize}(x_i) = \\frac{2(x_i - \\mu_{x_i})}{x_{i,max} - x_{i,min}} $$\n",
    "\n",
    "### Weight Initialization\n",
    "\n",
    "Methodology: Draw weights randomly from a gaussian (normal) distribution with mean $0$ and standard deviation $\\sigma$. Standard deviation $\\sigma$ determines the order of magnitude of your outputs. The order of magnitude also determines the peakiness of the intial probability distribution.\n",
    "\n",
    "A peaky initialized probability distribution (large $\\sigma$) will result in an opinionated distribution. Whereas a probability distribution with small peaks will start out more uncertain. **Most likely, you want to choose a small $\\sigma$ to start out uncertain and let the optimizer make it become more certain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance\n",
    "\n",
    "Classifiers will tend to memorize the data (**overfit**). To prevent this, test your classifier performance using a test set (small portion of the original dataset). However, this too has issues due to the trial and error approach of training a classifier. You may implicitly help your classifier learn your test set through your human decisions.\n",
    "\n",
    "Simple solution: Carve out another dataset as your validation set that you only measure performance against after you've chosen your final model.\n",
    "\n",
    "### Validation and Test Set Size\n",
    "\n",
    "Statisticians cover your ears: a change that affects 30 examples in your validation set is usually statistically significant and can be trusted.\n",
    "\n",
    "For most validation sets, people tend to hold back at least 30,000 examples since that mean accuracy changes $\\gt 0.1\\%$ should be statistically significant, giving you high enough resolution for your changes.\n",
    "\n",
    "**NOTE**: This is only true for datasets with **balanced** classes. Consider cross-validation if you have unbalanced classes.\n",
    "\n",
    "### Cross-Validation ($k$-fold)\n",
    "\n",
    "Cross-validation involves splitting your dataset into $k$ folds. You can then evaluate your model $k$ times, using $k - 1$ folds as training data and the left over fold as the test set.\n",
    "\n",
    "You can use different stratification strategies depending on how representative you want each fold to be.\n",
    "\n",
    "Cross-validation is often slow, so getting more data is often the right solution.\n",
    "\n",
    "![Cross-Validation](cross-validation.png)\n",
    "\n",
    "\n",
    "#### Statistically Significant Cross-Validation\n",
    "\n",
    "Number of folds $k$ has to be large enough (minimum 25-30) in order for the error rate $D_j = E_{1j} - E_{2j}$ between two classifiers $C1$ and $C2$ to be roughly normally distributed with mean $D_{TRUE}$.\n",
    "\n",
    "Given the performance of two classifiers $C1$ and $C2$ using $k=25$ fold cross-validation, the variance $\\sigma^2$ can be measured as:\n",
    "\n",
    "$$ \\sigma^2_{est} = \\frac{\\sum^{25}_{j=1}(D_j-D{av})^2}{24 \\cdot 25} $$\n",
    "\n",
    "The condifence interval for $D_{TRUE}$ is computed as:\n",
    "\n",
    "$$ D_{TRUE} = D_{av} \\pm \\sigma^2_{est}t_{(1-\\alpha)24} $$\n",
    "\n",
    "where $t_{(1-\\alpha)24}$ is the $t$ distribution coefficient found from a lookup table. $t_{(1-\\alpha)}$ denotes the cumulative probability of $(1-\\alpha)$, and 24 is the degrees of freedom ($k-1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Instead of computing the loss over all the data, compute a very bad estimate of the loss based on a **tiny, random sample** of the data. Use this sampled loss to compute the gradient, which may at times even result in more loss. Compensate by doing many times, taking smaller steps at a time.\n",
    "\n",
    "SGD scales well with both data and model size. It's fundamentally a bad optimizer; however, it's the only one that's fast enough in practice. As a result, there are many practical considerations one needs to take.\n",
    "\n",
    "![Stochastic Gradient Descent](stochastic-gradient-descent.png)\n",
    "\n",
    "### Helping SGD\n",
    "\n",
    "#### Normalizing Inputs\n",
    "\n",
    "Covered above. Recap: variables should have a mean of 0 and equal variance (small).\n",
    "\n",
    "#### Initial Weights\n",
    "\n",
    "Covered above. Recap: Should be random and normally distributed with a mean of 0 and equal variance (small).\n",
    "\n",
    "#### Momentum\n",
    "\n",
    "Each step taken in SGD occurs in a random direction. Rather than take each of those steps, utilize accumulated knowledge. Keep a running average $M$ of the gradient.\n",
    "\n",
    "$$ M \\leftarrow 0.9M + \\Delta\\mathcal{L} $$\n",
    "\n",
    "Use the running average instead of the direction of the current batch of the data:\n",
    "\n",
    "$$ -\\alpha \\Delta M(W,b) $$\n",
    "\n",
    "This momentum technique usually works pretty well and leads to better convergence.\n",
    "\n",
    "#### Learning Rate Decay\n",
    "\n",
    "Make the step smaller and smaller as your train by controlling the learning rate $\\alpha$. Some use an exponential decay. Some decrease the learning rate everytime there's a plateau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "### Learning Rate Tuning\n",
    "\n",
    "Having a higher learning rate will not necessarily mean you will get to a better model faster. In fact the opposite may be true: a lower learning rate may get you to a better model faster.\n",
    "\n",
    "Never confuse how quickly you learn with how well you train.\n",
    "\n",
    "![Learning Rate Tuning](learning-rate-tuning.png)\n",
    "\n",
    "### SGD \"Black Magic\"\n",
    "\n",
    "Many hyper-parameters:\n",
    "\n",
    "- Initial learning rate\n",
    "- Learning rate decay\n",
    "- Momentum\n",
    "- Batch size\n",
    "- Weight initialization\n",
    "\n",
    "In practice, when things don't work, **try lowering your learning rate first**.\n",
    "\n",
    "### Adagrad\n",
    "\n",
    "Learning is less sensitive to hyper-parameters:\n",
    "\n",
    "- <strike>Initial learning rate</strike>\n",
    "- <strike>Learning rate decay</strike>\n",
    "- <strike>Momentum</strike>\n",
    "- Batch size\n",
    "- Weight initialization\n",
    "\n",
    "However, it often tends to be a little worse than *precisely-tuned* SGD with momentum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
